# SAM3 Docker ä½¿ç”¨æŒ‡å—

æœ¬ç›®éŒ„åŒ…å« SAM3 çš„ Docker é…ç½®ï¼Œæ”¯æ´ **Ubuntu 24.04**ã€**ROS2 Jazzy Desktop**ã€**CUDA 12.6** å’Œ **Python 3.12**ã€‚

> **æ³¨æ„**: ä½¿ç”¨ Ubuntu 24.04 æ˜¯å› ç‚º ROS2 Jazzy åŸç”Ÿæ”¯æ´ Python 3.12ï¼Œè§£æ±ºäº† ROS Humble åªæ”¯æ´ Python 3.10 çš„é™åˆ¶ã€‚

## ğŸ“‹ ç³»çµ±éœ€æ±‚

### ç¡¬é«”è¦æ±‚
- NVIDIA GPU (å»ºè­° 16GB+ VRAM)
- 16GB+ RAM
- 50GB+ å¯ç”¨ç£ç¢Ÿç©ºé–“

### è»Ÿé«”è¦æ±‚
- Docker 20.10+
- Docker Compose 2.0+
- NVIDIA Docker Runtime (nvidia-docker2)
- **NVIDIA Driver 550+** (æ”¯æ´ CUDA 12.6+)

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. å®‰è£ Docker å’Œ NVIDIA Docker

```bash
# å®‰è£ Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# å®‰è£ NVIDIA Docker Runtime
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker

# é©—è­‰å®‰è£
docker run --rm --gpus all nvidia/cuda:12.6.0-base-ubuntu24.04 nvidia-smi
```

### 2. å…è¨± X11 é€£æ¥

```bash
# å…è¨±æœ¬åœ° Docker é€£æ¥ X11
xhost +local:docker
```

### 3. è¨­ç½® Hugging Face Token (å¯é¸)

```bash
# å¦‚æœéœ€è¦ä¸‹è¼‰ SAM3 æ¨¡å‹ï¼Œè¨­ç½®ä½ çš„ Hugging Face token
export HF_TOKEN="your_huggingface_token_here"
```

### 4. æ§‹å»º Docker æ˜ åƒ

```bash
cd /path/to/sam3/docker
docker-compose build
```

æˆ–ä½¿ç”¨ Docker ç›´æ¥æ§‹å»ºï¼š

```bash
cd /path/to/sam3
docker build -f docker/Dockerfile -t sam3:latest .
```

### 5. å•Ÿå‹•å®¹å™¨

#### é¸é … A: ä½¿ç”¨ docker-compose (æ¨è–¦)

```bash
cd /path/to/sam3/docker

# å•Ÿå‹•ä¸»å®¹å™¨ (äº’å‹•å¼)
docker-compose run --rm sam3

# æˆ–å•Ÿå‹• Jupyter notebook æœå‹™
docker-compose up sam3-jupyter

# èƒŒæ™¯é‹è¡Œ
docker-compose up -d sam3
docker-compose exec sam3 bash
```

#### é¸é … B: ä½¿ç”¨ docker run

```bash
docker run -it --rm \
    --gpus all \
    --network host \
    --ipc=host \
    --privileged \
    -e DISPLAY=$DISPLAY \
    -e NVIDIA_VISIBLE_DEVICES=all \
    -e NVIDIA_DRIVER_CAPABILITIES=all \
    -v /tmp/.X11-unix:/tmp/.X11-unix:rw \
    -v $(pwd)/..:/workspace/sam3 \
    -v ~/.cache/huggingface:/workspace/.cache/huggingface \
    -v /dev/shm:/dev/shm \
    -w /workspace/sam3 \
    sam3:latest \
    /bin/bash
```

## ğŸ“¦ å®¹å™¨å…§ä½¿ç”¨

### å®‰è£ SAM3

å®¹å™¨å•Ÿå‹•å¾Œï¼ŒSAM3 ä»£ç¢¼å·²ç¶“æ›è¼‰åˆ° `/workspace/sam3`ï¼š

```bash
# é€²å…¥å®¹å™¨å¾Œ
cd /workspace/sam3

# å®‰è£ SAM3 (editable mode)
pip install -e .

# æˆ–å®‰è£å®Œæ•´é–‹ç™¼ä¾è³´
pip install -e ".[notebooks,dev]"
```

### é©—è­‰å®‰è£

```bash
# æª¢æŸ¥ CUDA
python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}')"
python -c "import torch; print(f'GPU Count: {torch.cuda.device_count()}')"

# æª¢æŸ¥ ROS
printenv | grep ROS
ros2 --version

# æª¢æŸ¥ SAM3
python -c "from sam3.model_builder import build_sam3_image_model; print('SAM3 import successful!')"
```

### é‹è¡Œç¯„ä¾‹

```bash
# é‹è¡Œ Python è…³æœ¬
cd /workspace/sam3
python examples/your_script.py

# å•Ÿå‹• Jupyter notebook
jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root

# é‹è¡Œ ROS ç¯€é» (å¦‚æœä½ å‰µå»ºäº† ROS åŒ…)
source /opt/ros/humble/setup.bash
ros2 run your_package your_node
```

## ğŸ¯ å¸¸ç”¨æ“ä½œ

### é€²å…¥æ­£åœ¨é‹è¡Œçš„å®¹å™¨

```bash
# ä½¿ç”¨ docker-compose
docker-compose exec sam3 bash

# æˆ–ä½¿ç”¨ docker
docker exec -it sam3_container bash
```

### æŸ¥çœ‹æ—¥èªŒ

```bash
# æŸ¥çœ‹å®¹å™¨æ—¥èªŒ
docker-compose logs -f sam3

# æŸ¥çœ‹ Jupyter æ—¥èªŒ
docker-compose logs -f sam3-jupyter
```

### åœæ­¢å’Œåˆªé™¤å®¹å™¨

```bash
# åœæ­¢å®¹å™¨
docker-compose down

# åœæ­¢ä¸¦åˆªé™¤æ‰€æœ‰æ•¸æ“š
docker-compose down -v
```

### é‡æ–°æ§‹å»ºæ˜ åƒ

```bash
# é‡æ–°æ§‹å»ºï¼ˆä¸ä½¿ç”¨å¿«å–ï¼‰
docker-compose build --no-cache

# æ§‹å»ºç‰¹å®šæœå‹™
docker-compose build sam3
```

## ğŸ”§ é…ç½®èªªæ˜

### Volume æ›è¼‰

åœ¨ `docker-compose.yml` ä¸­é…ç½®äº†ä»¥ä¸‹æ›è¼‰ï¼š

```yaml
volumes:
  # SAM3 æºä»£ç¢¼ (å¯è®€å¯«)
  - ../:/workspace/sam3
  
  # X11 é¡¯ç¤º
  - /tmp/.X11-unix:/tmp/.X11-unix:rw
  
  # Hugging Face æ¨¡å‹å¿«å–
  - ~/.cache/huggingface:/workspace/.cache/huggingface
  
  # æ•¸æ“šé›†ç›®éŒ„ (å”¯è®€)
  - ~/datasets:/workspace/datasets:ro
  
  # å…±äº«è¨˜æ†¶é«”
  - /dev/shm:/dev/shm
```

### ç’°å¢ƒè®Šæ•¸

```yaml
environment:
  - DISPLAY=${DISPLAY}                    # X11 é¡¯ç¤º
  - NVIDIA_VISIBLE_DEVICES=all            # æ‰€æœ‰ GPU
  - HF_TOKEN=${HF_TOKEN}                  # Hugging Face token
  - ROS_DOMAIN_ID=0                       # ROS domain ID
  - CUDA_VISIBLE_DEVICES=0                # æŒ‡å®šä½¿ç”¨çš„ GPU
```

### ç¶²è·¯æ¨¡å¼

ä½¿ç”¨ `network_mode: host` ä»¥ä¾¿ï¼š
- å®¹å™¨å¯ä»¥è¨ªå•ä¸»æ©Ÿçš„æ‰€æœ‰ç¶²è·¯ç«¯å£
- ROS ç¯€é»å¯ä»¥äº’ç›¸ç™¼ç¾
- ç°¡åŒ–ç¶²è·¯é…ç½®

å¦‚æœéœ€è¦éš”é›¢ç¶²è·¯ï¼Œå¯ä»¥æ”¹ç”¨ bridge æ¨¡å¼ï¼š

```yaml
network_mode: bridge
ports:
  - "8888:8888"  # Jupyter
  - "6006:6006"  # TensorBoard
```

## ğŸ› æ•…éšœæ’é™¤

### å•é¡Œ 1: CUDA ä¸å¯ç”¨

```bash
# æª¢æŸ¥ NVIDIA driver
nvidia-smi

# æª¢æŸ¥ Docker GPU æ”¯æ´
docker run --rm --gpus all nvidia/cuda:12.6.0-base-ubuntu22.04 nvidia-smi

# é‡å•Ÿ Docker
sudo systemctl restart docker
```

### å•é¡Œ 2: X11 é¡¯ç¤ºéŒ¯èª¤

```bash
# é‡æ–°å…è¨± X11 é€£æ¥
xhost +local:docker

# æª¢æŸ¥ DISPLAY è®Šæ•¸
echo $DISPLAY

# åœ¨å®¹å™¨å…§æ¸¬è©¦
xclock  # æ‡‰è©²é¡¯ç¤ºä¸€å€‹æ™‚é˜è¦–çª—
```

### å•é¡Œ 3: è¨˜æ†¶é«”ä¸è¶³

```bash
# å¢åŠ å…±äº«è¨˜æ†¶é«”å¤§å°
docker run --shm-size=8gb ...

# æˆ–åœ¨ docker-compose.yml ä¸­æ·»åŠ 
shm_size: '8gb'
```

### å•é¡Œ 4: æ¬Šé™å•é¡Œ

```bash
# ä»¥ç•¶å‰ç”¨æˆ¶é‹è¡Œå®¹å™¨
docker-compose run --rm --user "$(id -u):$(id -g)" sam3

# æˆ–ä¿®æ”¹ docker-compose.yml
user: "${UID}:${GID}"
```

### å•é¡Œ 5: Hugging Face ä¸‹è¼‰å¤±æ•—

```bash
# è¨­ç½® token
export HF_TOKEN="your_token"

# æˆ–åœ¨å®¹å™¨å…§æ‰‹å‹•ç™»éŒ„
huggingface-cli login

# æª¢æŸ¥ç¶²è·¯é€£æ¥
curl https://huggingface.co
```

## ğŸ“ é€²éšä½¿ç”¨

### å¤š GPU é…ç½®

```yaml
environment:
  # ä½¿ç”¨ç‰¹å®š GPU
  - CUDA_VISIBLE_DEVICES=0,1

deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          device_ids: ['0', '1']
          capabilities: [gpu]
```

### è³‡æºé™åˆ¶

```yaml
deploy:
  resources:
    limits:
      cpus: '8'
      memory: 32G
    reservations:
      cpus: '4'
      memory: 16G
```

### è‡ªå®šç¾©å•Ÿå‹•è…³æœ¬

ä¿®æ”¹ `entrypoint.sh` æ·»åŠ è‡ªå®šç¾©åˆå§‹åŒ–é‚è¼¯ï¼š

```bash
#!/bin/bash
set -e

source /opt/ros/humble/setup.bash

# è‡ªå‹•å®‰è£ SAM3
if [ ! -f "/workspace/sam3/.installed" ]; then
    cd /workspace/sam3
    pip install -e .
    touch .installed
fi

# å…¶ä»–åˆå§‹åŒ–...

exec "$@"
```

## ğŸ“š ç›¸é—œè³‡æº

- [SAM3 GitHub](https://github.com/facebookresearch/sam3)
- [SAM3 Hugging Face](https://huggingface.co/facebook/sam3)
- [ROS Humble æ–‡æª”](https://docs.ros.org/en/humble/)
- [NVIDIA Docker](https://github.com/NVIDIA/nvidia-docker)
- [Docker Compose](https://docs.docker.com/compose/)

## ğŸ¤ è²¢ç»

å¦‚æœ‰å•é¡Œæˆ–æ”¹é€²å»ºè­°ï¼Œè«‹æäº¤ Issue æˆ– Pull Requestã€‚

---

**å»ºç«‹æ™‚é–“**: 2025-11-25
**ç¶­è­·è€…**: Your Name
