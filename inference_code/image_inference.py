#!/usr/bin/env python3
"""
SAM3 åœ–ç‰‡æ¨è«–è…³æœ¬
================
åŸºæ–¼å®˜æ–¹ examples/sam3_image_predictor_example.ipynb ä¿®æ”¹

ä½¿ç”¨æ–¹æ³•:
    python image_inference.py --image <åœ–ç‰‡è·¯å¾‘> --prompt "è¦åˆ†å‰²çš„ç‰©ä»¶"

ç¯„ä¾‹:
    python image_inference.py --image ../assets/images/test_image.jpg --prompt "shoe"
    python image_inference.py --image ../assets/images/truck.jpg --prompt "wheel"
"""

import argparse
import os
import sys

import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨é GUI å¾Œç«¯
import matplotlib.pyplot as plt
import numpy as np
import torch
from PIL import Image

# ç¢ºä¿å¯ä»¥ import sam3
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

import sam3
from sam3 import build_sam3_image_model
from sam3.model.sam3_image_processor import Sam3Processor
from sam3.visualization_utils import plot_results

# è¨­å®šè¼¸å‡ºç›®éŒ„
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), "outputs")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# è¨­å®š TF32 ä»¥æå‡ Ampere GPU æ•ˆèƒ½
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True


def parse_args():
    parser = argparse.ArgumentParser(description="SAM3 åœ–ç‰‡æ¨è«–")
    parser.add_argument(
        "--image", 
        type=str, 
        default=None,
        help="è¼¸å…¥åœ–ç‰‡è·¯å¾‘"
    )
    parser.add_argument(
        "--prompt", 
        type=str, 
        default="person",
        help="æ–‡å­—æç¤º (è¦åˆ†å‰²çš„ç‰©ä»¶)"
    )
    parser.add_argument(
        "--confidence", 
        type=float, 
        default=0.5,
        help="ä¿¡å¿ƒé–¾å€¼ (0-1)"
    )
    parser.add_argument(
        "--output", 
        type=str, 
        default=None,
        help="è¼¸å‡ºåœ–ç‰‡è·¯å¾‘ (é è¨­è‡ªå‹•ç”Ÿæˆ)"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="é‹ç®—è£ç½® (cuda/cpu)"
    )
    return parser.parse_args()


def main():
    args = parse_args()
    
    print("=" * 60)
    print("SAM3 åœ–ç‰‡æ¨è«–")
    print("=" * 60)
    
    # æª¢æŸ¥ GPU
    if args.device == "cuda" and torch.cuda.is_available():
        print(f"âœ… ä½¿ç”¨ GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸  ä½¿ç”¨ CPU (é€Ÿåº¦è¼ƒæ…¢)")
    
    # è¨­å®šåœ–ç‰‡è·¯å¾‘
    sam3_root = os.path.join(os.path.dirname(sam3.__file__), "..")
    if args.image is None:
        # ä½¿ç”¨é è¨­æ¸¬è©¦åœ–ç‰‡
        image_path = os.path.join(sam3_root, "assets", "images", "test_image.jpg")
    else:
        image_path = args.image
        if not os.path.isabs(image_path):
            image_path = os.path.abspath(image_path)
    
    if not os.path.exists(image_path):
        print(f"âŒ æ‰¾ä¸åˆ°åœ–ç‰‡: {image_path}")
        sys.exit(1)
    
    print(f"\nğŸ“· è¼‰å…¥åœ–ç‰‡: {image_path}")
    image = Image.open(image_path)
    print(f"   å°ºå¯¸: {image.size}")
    
    # è¼‰å…¥æ¨¡å‹
    print("\nğŸ”§ è¼‰å…¥æ¨¡å‹...")
    bpe_path = os.path.join(sam3_root, "assets", "bpe_simple_vocab_16e6.txt.gz")
    
    with torch.autocast("cuda", dtype=torch.bfloat16):
        model = build_sam3_image_model(bpe_path=bpe_path, device=args.device)
        processor = Sam3Processor(model, confidence_threshold=args.confidence)
        
        # è¨­å®šåœ–ç‰‡
        print("ğŸ–¼ï¸  è™•ç†åœ–ç‰‡...")
        inference_state = processor.set_image(image)
        
        # ä½¿ç”¨æ–‡å­—æç¤ºé€²è¡Œåˆ†å‰²
        print(f"ğŸ” ä½¿ç”¨æ–‡å­—æç¤º: '{args.prompt}'")
        inference_state = processor.set_text_prompt(
            state=inference_state, 
            prompt=args.prompt
        )
    
    # å–å¾—çµæœ
    masks = inference_state.get("masks")
    boxes = inference_state.get("boxes")
    scores = inference_state.get("scores")
    
    num_objects = len(masks) if masks is not None else 0
    print(f"\nğŸ“Š åˆ†å‰²çµæœ:")
    print(f"   æ‰¾åˆ° {num_objects} å€‹ç‰©ä»¶")
    if scores is not None and len(scores) > 0:
        scores_list = scores.cpu().tolist() if hasattr(scores, 'cpu') else scores
        print(f"   åˆ†æ•¸: {[f'{s:.3f}' for s in scores_list]}")
    
    # å„²å­˜è¦–è¦ºåŒ–çµæœ
    if args.output is None:
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        prompt_safe = args.prompt.replace(" ", "_")[:20]
        output_path = os.path.join(OUTPUT_DIR, f"{base_name}_{prompt_safe}_result.png")
    else:
        output_path = args.output
    
    plot_results(image, inference_state)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"\nâœ… çµæœå·²å„²å­˜åˆ°: {output_path}")
    print("=" * 60)


if __name__ == "__main__":
    main()
